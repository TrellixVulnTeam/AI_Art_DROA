{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part2_Dotrenowywanie.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVwX4IWNJsNx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ea979a-43ff-45db-c1bb-b8f11d67e3b6"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVDPbiOsJ73z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fdd2051-66a0-40fc-e707-af753b98943d"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"355M\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 444Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 95.4Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 309Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:05, 244Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 742Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 98.7Mit/s]                                                \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 138Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCqpnU9xJ751",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c23931-6a9c-462c-ecc3-7d73a3399791"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4DqxArSYtJe"
      },
      "source": [
        "def mirek_test(a):\n",
        "  return a+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXcT5sH2YtrA",
        "outputId": "d4c909d4-3850-4541-bed2-e5de5c282a87"
      },
      "source": [
        "mirek_test(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DLJlcCEakDO",
        "outputId": "615329d2-dc9d-4bcf-d002-a306b5989e3a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qTY3vUta44G",
        "outputId": "e7a16c0b-0b7a-407b-d8a5-80230accdb44"
      },
      "source": [
        "!ls /content/gdrive/My\\ Drive/*.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/gdrive/My Drive/banksterzy.py'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hINr8jvsa4_l"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIfE8dL_Z0w7"
      },
      "source": [
        "import banksterzy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xnxgZrXZ03J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuS09nrTYtt1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShjdhlGdJ78Z"
      },
      "source": [
        "file_name = \"model_v01_clean.txt\"\n",
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEQS1FAjJ7-u"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='mm_model_355M_v01')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGZLMgq-J8BL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8ab7f4-f7c8-48a8-bb73-ca32a1dd642c"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='355M',\n",
        "              restore_from = 'latest',\n",
        "              steps=10000,\n",
        "              run_name='mm_model_355M_v01',\n",
        "              print_every=10,\n",
        "              sample_every=2000,\n",
        "              save_every=1000\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "Loading checkpoint checkpoint/mm_model_355M_v01/model-15000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/mm_model_355M_v01/model-15000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:09<00:00,  9.95s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 2337163 tokens\n",
            "Training...\n",
            "Saving checkpoint/mm_model_355M_v01/model-15000\n",
            "[15010 | 32.89] loss=1.25 avg=1.25\n",
            "[15020 | 47.70] loss=0.28 avg=0.76\n",
            "[15030 | 62.62] loss=0.97 avg=0.83\n",
            "[15040 | 77.65] loss=1.65 avg=1.04\n",
            "[15050 | 92.82] loss=0.55 avg=0.94\n",
            "[15060 | 108.09] loss=0.76 avg=0.91\n",
            "[15070 | 123.46] loss=0.21 avg=0.80\n",
            "[15080 | 138.91] loss=0.48 avg=0.76\n",
            "[15090 | 154.47] loss=0.65 avg=0.75\n",
            "[15100 | 170.06] loss=0.46 avg=0.72\n",
            "[15110 | 185.74] loss=0.77 avg=0.72\n",
            "[15120 | 201.48] loss=0.26 avg=0.68\n",
            "[15130 | 217.29] loss=0.38 avg=0.66\n",
            "[15140 | 233.13] loss=0.44 avg=0.64\n",
            "[15150 | 249.00] loss=0.12 avg=0.60\n",
            "[15160 | 264.89] loss=0.36 avg=0.59\n",
            "[15170 | 280.83] loss=0.43 avg=0.58\n",
            "[15180 | 296.80] loss=0.54 avg=0.58\n",
            "[15190 | 312.83] loss=0.39 avg=0.56\n",
            "[15200 | 328.87] loss=0.46 avg=0.56\n",
            "[15210 | 344.95] loss=0.33 avg=0.55\n",
            "[15220 | 361.04] loss=0.70 avg=0.55\n",
            "[15230 | 377.16] loss=1.41 avg=0.60\n",
            "[15240 | 393.30] loss=0.47 avg=0.59\n",
            "[15250 | 409.46] loss=0.32 avg=0.58\n",
            "[15260 | 425.67] loss=1.20 avg=0.60\n",
            "[15270 | 441.88] loss=1.27 avg=0.63\n",
            "[15280 | 458.12] loss=0.54 avg=0.63\n",
            "[15290 | 474.34] loss=0.67 avg=0.63\n",
            "[15300 | 490.58] loss=0.18 avg=0.61\n",
            "[15310 | 506.80] loss=1.71 avg=0.65\n",
            "[15320 | 523.04] loss=0.40 avg=0.65\n",
            "[15330 | 539.25] loss=0.10 avg=0.63\n",
            "[15340 | 555.51] loss=1.24 avg=0.65\n",
            "[15350 | 571.75] loss=0.77 avg=0.65\n",
            "[15360 | 587.99] loss=0.36 avg=0.64\n",
            "[15370 | 604.21] loss=0.49 avg=0.64\n",
            "[15380 | 620.44] loss=0.84 avg=0.64\n",
            "[15390 | 636.71] loss=0.67 avg=0.64\n",
            "[15400 | 652.98] loss=0.35 avg=0.64\n",
            "[15410 | 669.25] loss=0.51 avg=0.63\n",
            "[15420 | 685.49] loss=0.26 avg=0.62\n",
            "[15430 | 701.78] loss=0.47 avg=0.62\n",
            "[15440 | 718.03] loss=0.37 avg=0.61\n",
            "[15450 | 734.26] loss=0.51 avg=0.61\n",
            "[15460 | 750.52] loss=0.10 avg=0.59\n",
            "[15470 | 766.76] loss=0.31 avg=0.59\n",
            "[15480 | 783.03] loss=0.59 avg=0.59\n",
            "[15490 | 799.31] loss=0.34 avg=0.58\n",
            "[15500 | 815.61] loss=0.42 avg=0.58\n",
            "[15510 | 831.85] loss=0.18 avg=0.57\n",
            "[15520 | 848.10] loss=0.37 avg=0.56\n",
            "[15530 | 864.38] loss=0.36 avg=0.56\n",
            "[15540 | 880.65] loss=0.33 avg=0.55\n",
            "[15550 | 896.92] loss=0.53 avg=0.55\n",
            "[15560 | 913.22] loss=0.17 avg=0.54\n",
            "[15570 | 929.51] loss=0.62 avg=0.54\n",
            "[15580 | 945.80] loss=0.30 avg=0.54\n",
            "[15590 | 962.11] loss=0.58 avg=0.54\n",
            "[15600 | 978.43] loss=0.14 avg=0.53\n",
            "[15610 | 994.69] loss=0.40 avg=0.53\n",
            "[15620 | 1010.97] loss=0.51 avg=0.53\n",
            "[15630 | 1027.25] loss=1.69 avg=0.55\n",
            "[15640 | 1043.52] loss=0.64 avg=0.55\n",
            "[15650 | 1059.74] loss=0.77 avg=0.56\n",
            "[15660 | 1076.03] loss=0.54 avg=0.56\n",
            "[15670 | 1092.34] loss=1.39 avg=0.57\n",
            "[15680 | 1108.66] loss=0.60 avg=0.58\n",
            "[15690 | 1124.93] loss=0.48 avg=0.57\n",
            "[15700 | 1141.25] loss=1.13 avg=0.58\n",
            "[15710 | 1157.59] loss=0.37 avg=0.58\n",
            "[15720 | 1173.90] loss=0.78 avg=0.58\n",
            "[15730 | 1190.15] loss=0.52 avg=0.58\n",
            "[15740 | 1206.42] loss=1.55 avg=0.60\n",
            "[15750 | 1222.71] loss=0.52 avg=0.60\n",
            "[15760 | 1238.95] loss=0.56 avg=0.60\n",
            "[15770 | 1255.18] loss=0.47 avg=0.60\n",
            "[15780 | 1271.42] loss=0.31 avg=0.59\n",
            "[15790 | 1287.65] loss=1.35 avg=0.61\n",
            "[15800 | 1303.91] loss=0.70 avg=0.61\n",
            "[15810 | 1320.17] loss=0.38 avg=0.60\n",
            "[15820 | 1336.44] loss=0.31 avg=0.60\n",
            "[15830 | 1352.69] loss=0.17 avg=0.59\n",
            "[15840 | 1368.93] loss=1.76 avg=0.61\n",
            "[15850 | 1385.16] loss=0.60 avg=0.61\n",
            "[15860 | 1401.37] loss=0.20 avg=0.60\n",
            "[15870 | 1417.60] loss=0.32 avg=0.60\n",
            "[15880 | 1433.84] loss=0.53 avg=0.60\n",
            "[15890 | 1450.06] loss=0.54 avg=0.60\n",
            "[15900 | 1466.32] loss=0.11 avg=0.59\n",
            "[15910 | 1482.57] loss=0.58 avg=0.59\n",
            "[15920 | 1498.81] loss=0.74 avg=0.59\n",
            "[15930 | 1515.03] loss=0.43 avg=0.59\n",
            "[15940 | 1531.26] loss=1.20 avg=0.60\n",
            "[15950 | 1547.48] loss=0.30 avg=0.59\n",
            "[15960 | 1563.70] loss=1.93 avg=0.61\n",
            "[15970 | 1579.91] loss=0.62 avg=0.61\n",
            "[15980 | 1596.14] loss=0.31 avg=0.61\n",
            "[15990 | 1612.34] loss=0.57 avg=0.61\n",
            "[16000 | 1628.55] loss=1.42 avg=0.62\n",
            "Saving checkpoint/mm_model_355M_v01/model-16000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "======== SAMPLE 1 ========\n",
            "zy\n",
            "A po wsi cicha noc okrutną?\n",
            "Giniecie, a dla mnie się w dumie\n",
            "Rycerskiego równowagę!\n",
            "O miłujące serdeczną\n",
            "Z pieczącą w duszach i thetrowagę,\n",
            "Gdy go tam orla okrutną\n",
            "Za orłem złocić słowik —\n",
            "I piecząc 'bądź znika'\n",
            "O świcie będzie moje -\n",
            "Ja bądź znika!\n",
            "Wreszcie w gęste mi rzucające\n",
            "Chmielnicze w okręg przymknięty,\n",
            "Bryzgają srebrne pochłoną,\n",
            "Pomyśli, zdumiały, jak słup kawały\n",
            "Z rozczarowań chustką wawrzynu\n",
            "Daleki koniec manfredzie\n",
            "W koniec prawdy szczerzej wieżej,\n",
            "A żywe ciało w gwiazd biegu\n",
            "Górnymi grzmi po gwiazd przymknięty,\n",
            "Bielą się szum ten zawsze boju,\n",
            "Księżyc wzniesione z nieba ciemną,\n",
            "Wszystkie światła miało koniec\n",
            "I krzesał bram nieszczęśliwy,\n",
            "Milknęło biel zaćmione kłosy,\n",
            "A krajobraz w głąb przypięły\n",
            "Na drogi krosną zieloną,\n",
            "Drogi wiek pokryły w dole,\n",
            "Dźwięczy za drzewa bok miły,\n",
            "Dziwna, żałość sam z sobą pnie\n",
            "I wywuśliśmy wszystkie gwiazdy,\n",
            "I że żyjmy ćmią 'bądź' ból,\n",
            "Między niemi w głębi srebrzystej\n",
            "Na drodze świata społeczność,\n",
            "W 'aż z dala' kraj dalekich ech,\n",
            "Z 'artem', w 'hufiec artem sztuki',\n",
            "By 'błysłem' na 'pograniku'\n",
            "Złotym ujrzeniem snu.\n",
            "Gdy przez 'żadnej'' — rzekł wreście — ''abstrachu'' —\n",
            "W 'artem'. piękność i 'mbita''.\n",
            "Tu znikałbym otworzył gwiazdom na ziemi —\n",
            "Penitent pełen zacięty, pełen złóż tomi\n",
            "I ukazałeś dotknąłeś pełnemi,\n",
            "Aby z dumnem odetchnął powinność zgasł brzeg.\n",
            "Szwagą złowieszcze w tym żałobie i zły,\n",
            "Szwagą złowieszcze w tym iść bezprysną globie,\n",
            "By 'bratniezka w świata przeszła życia pleśń''.\n",
            "Gdy 'artem' przyjął, ale 'artem' wspólnej dłoni\n",
            "Smutnych i skruszony potężnej pogoni —\n",
            "Szwagą złowieszcze w tym iść bezprysną globie,\n",
            "A wszystkie wszyscy, co jest podpatrzony\n",
            "Z mętnych liści złotem\n",
            "\n",
            "[16010 | 1676.97] loss=0.30 avg=0.62\n",
            "[16020 | 1693.08] loss=0.71 avg=0.62\n",
            "[16030 | 1709.24] loss=0.50 avg=0.62\n",
            "[16040 | 1725.44] loss=1.72 avg=0.63\n",
            "[16050 | 1741.63] loss=0.34 avg=0.63\n",
            "[16060 | 1757.84] loss=0.23 avg=0.62\n",
            "[16070 | 1774.05] loss=0.22 avg=0.62\n",
            "[16080 | 1790.30] loss=0.32 avg=0.61\n",
            "[16090 | 1806.57] loss=1.46 avg=0.63\n",
            "[16100 | 1822.81] loss=0.71 avg=0.63\n",
            "[16110 | 1839.06] loss=0.73 avg=0.63\n",
            "[16120 | 1855.29] loss=1.23 avg=0.64\n",
            "[16130 | 1871.53] loss=1.49 avg=0.65\n",
            "[16140 | 1887.80] loss=0.52 avg=0.65\n",
            "[16150 | 1904.07] loss=0.71 avg=0.65\n",
            "[16160 | 1920.34] loss=1.47 avg=0.66\n",
            "[16170 | 1936.62] loss=0.86 avg=0.66\n",
            "[16180 | 1952.92] loss=1.02 avg=0.67\n",
            "[16190 | 1969.20] loss=2.03 avg=0.69\n",
            "[16200 | 1985.50] loss=1.01 avg=0.69\n",
            "[16210 | 2001.84] loss=0.19 avg=0.69\n",
            "[16220 | 2018.15] loss=1.58 avg=0.70\n",
            "[16230 | 2034.45] loss=0.14 avg=0.69\n",
            "[16240 | 2050.74] loss=0.46 avg=0.69\n",
            "[16250 | 2067.01] loss=0.67 avg=0.69\n",
            "[16260 | 2083.27] loss=0.47 avg=0.68\n",
            "[16270 | 2099.51] loss=0.66 avg=0.68\n",
            "[16280 | 2115.79] loss=0.20 avg=0.68\n",
            "[16290 | 2132.07] loss=0.58 avg=0.68\n",
            "[16300 | 2148.38] loss=0.57 avg=0.67\n",
            "[16310 | 2164.71] loss=0.41 avg=0.67\n",
            "[16320 | 2181.05] loss=0.39 avg=0.67\n",
            "[16330 | 2197.38] loss=1.49 avg=0.68\n",
            "[16340 | 2213.71] loss=0.23 avg=0.67\n",
            "[16350 | 2229.98] loss=0.60 avg=0.67\n",
            "[16360 | 2246.25] loss=0.32 avg=0.67\n",
            "[16370 | 2262.54] loss=0.52 avg=0.66\n",
            "[16380 | 2278.77] loss=0.92 avg=0.67\n",
            "[16390 | 2295.06] loss=1.19 avg=0.67\n",
            "[16400 | 2311.33] loss=0.41 avg=0.67\n",
            "[16410 | 2327.63] loss=1.79 avg=0.69\n",
            "[16420 | 2343.94] loss=0.10 avg=0.68\n",
            "[16430 | 2360.27] loss=0.93 avg=0.68\n",
            "[16440 | 2376.60] loss=0.35 avg=0.68\n",
            "[16450 | 2392.90] loss=0.26 avg=0.67\n",
            "[16460 | 2409.15] loss=0.35 avg=0.67\n",
            "[16470 | 2425.40] loss=0.20 avg=0.66\n",
            "[16480 | 2441.66] loss=0.45 avg=0.66\n",
            "[16490 | 2457.97] loss=0.60 avg=0.66\n",
            "[16500 | 2474.28] loss=0.36 avg=0.65\n",
            "[16510 | 2490.59] loss=0.12 avg=0.65\n",
            "[16520 | 2506.89] loss=0.58 avg=0.65\n",
            "[16530 | 2523.20] loss=0.27 avg=0.64\n",
            "[16540 | 2539.50] loss=1.60 avg=0.65\n",
            "[16550 | 2555.77] loss=0.37 avg=0.65\n",
            "[16560 | 2572.07] loss=0.17 avg=0.64\n",
            "[16570 | 2588.35] loss=0.64 avg=0.64\n",
            "[16580 | 2604.66] loss=0.48 avg=0.64\n",
            "[16590 | 2620.93] loss=0.18 avg=0.64\n",
            "[16600 | 2637.23] loss=0.22 avg=0.63\n",
            "[16610 | 2653.51] loss=0.48 avg=0.63\n",
            "[16620 | 2669.83] loss=0.50 avg=0.63\n",
            "[16630 | 2686.27] loss=0.47 avg=0.63\n",
            "[16640 | 2702.74] loss=1.24 avg=0.63\n",
            "[16650 | 2719.12] loss=0.60 avg=0.63\n",
            "[16660 | 2735.43] loss=0.68 avg=0.63\n",
            "[16670 | 2751.80] loss=0.32 avg=0.63\n",
            "[16680 | 2768.18] loss=0.49 avg=0.63\n",
            "[16690 | 2784.57] loss=0.51 avg=0.63\n",
            "[16700 | 2800.99] loss=0.22 avg=0.62\n",
            "[16710 | 2817.39] loss=0.26 avg=0.62\n",
            "[16720 | 2833.78] loss=1.10 avg=0.62\n",
            "[16730 | 2850.13] loss=0.86 avg=0.63\n",
            "[16740 | 2866.46] loss=1.15 avg=0.63\n",
            "[16750 | 2882.78] loss=0.61 avg=0.63\n",
            "[16760 | 2899.13] loss=0.57 avg=0.63\n",
            "[16770 | 2915.47] loss=1.12 avg=0.64\n",
            "[16780 | 2931.76] loss=0.31 avg=0.63\n",
            "[16790 | 2948.08] loss=0.87 avg=0.64\n",
            "[16800 | 2964.41] loss=0.28 avg=0.63\n",
            "[16810 | 2980.74] loss=0.34 avg=0.63\n",
            "[16820 | 2997.12] loss=0.85 avg=0.63\n",
            "[16830 | 3013.47] loss=0.39 avg=0.63\n",
            "[16840 | 3029.85] loss=0.53 avg=0.63\n",
            "[16850 | 3046.20] loss=0.23 avg=0.62\n",
            "[16860 | 3062.62] loss=0.24 avg=0.62\n",
            "[16870 | 3079.02] loss=0.65 avg=0.62\n",
            "[16880 | 3095.40] loss=0.72 avg=0.62\n",
            "[16890 | 3111.76] loss=0.73 avg=0.62\n",
            "[16900 | 3128.13] loss=0.94 avg=0.62\n",
            "[16910 | 3144.47] loss=0.37 avg=0.62\n",
            "[16920 | 3160.81] loss=0.42 avg=0.62\n",
            "[16930 | 3177.15] loss=0.47 avg=0.62\n",
            "[16940 | 3193.52] loss=2.20 avg=0.64\n",
            "[16950 | 3209.85] loss=0.82 avg=0.64\n",
            "[16960 | 3226.17] loss=0.29 avg=0.63\n",
            "[16970 | 3242.48] loss=0.26 avg=0.63\n",
            "[16980 | 3258.82] loss=0.17 avg=0.62\n",
            "[16990 | 3275.15] loss=1.79 avg=0.64\n",
            "[17000 | 3291.46] loss=0.17 avg=0.63\n",
            "Saving checkpoint/mm_model_355M_v01/model-17000\n",
            "[17010 | 3314.56] loss=0.37 avg=0.63\n",
            "[17020 | 3331.18] loss=0.87 avg=0.63\n",
            "[17030 | 3347.62] loss=0.95 avg=0.64\n",
            "[17040 | 3363.92] loss=1.11 avg=0.64\n",
            "[17050 | 3380.22] loss=0.70 avg=0.64\n",
            "[17060 | 3396.59] loss=0.18 avg=0.64\n",
            "[17070 | 3413.00] loss=0.28 avg=0.63\n",
            "[17080 | 3429.42] loss=0.73 avg=0.63\n",
            "[17090 | 3445.79] loss=0.43 avg=0.63\n",
            "[17100 | 3462.09] loss=0.41 avg=0.63\n",
            "[17110 | 3478.40] loss=0.18 avg=0.62\n",
            "[17120 | 3494.72] loss=1.27 avg=0.63\n",
            "[17130 | 3511.11] loss=1.49 avg=0.64\n",
            "[17140 | 3527.54] loss=0.67 avg=0.64\n",
            "[17150 | 3543.93] loss=0.55 avg=0.64\n",
            "[17160 | 3560.28] loss=0.27 avg=0.64\n",
            "[17170 | 3576.59] loss=0.36 avg=0.63\n",
            "[17180 | 3592.91] loss=0.25 avg=0.63\n",
            "[17190 | 3609.26] loss=0.21 avg=0.62\n",
            "[17200 | 3625.67] loss=0.79 avg=0.63\n",
            "[17210 | 3642.11] loss=0.35 avg=0.62\n",
            "[17220 | 3658.52] loss=0.23 avg=0.62\n",
            "[17230 | 3674.86] loss=0.38 avg=0.62\n",
            "[17240 | 3691.20] loss=0.32 avg=0.61\n",
            "[17250 | 3707.51] loss=0.22 avg=0.61\n",
            "[17260 | 3723.86] loss=0.44 avg=0.61\n",
            "[17270 | 3740.18] loss=0.73 avg=0.61\n",
            "[17280 | 3756.49] loss=0.97 avg=0.61\n",
            "[17290 | 3772.80] loss=1.51 avg=0.62\n",
            "[17300 | 3789.14] loss=0.25 avg=0.62\n",
            "[17310 | 3805.52] loss=1.12 avg=0.62\n",
            "[17320 | 3821.94] loss=0.22 avg=0.62\n",
            "[17330 | 3838.36] loss=0.74 avg=0.62\n",
            "[17340 | 3854.72] loss=0.43 avg=0.62\n",
            "[17350 | 3871.10] loss=0.88 avg=0.62\n",
            "[17360 | 3887.45] loss=0.80 avg=0.62\n",
            "[17370 | 3903.79] loss=0.79 avg=0.62\n",
            "[17380 | 3920.10] loss=0.64 avg=0.62\n",
            "[17390 | 3936.43] loss=0.63 avg=0.62\n",
            "[17400 | 3952.81] loss=0.31 avg=0.62\n",
            "[17410 | 3969.23] loss=0.71 avg=0.62\n",
            "[17420 | 3985.62] loss=0.44 avg=0.62\n",
            "[17430 | 4001.96] loss=0.58 avg=0.62\n",
            "[17440 | 4018.29] loss=0.68 avg=0.62\n",
            "[17450 | 4034.59] loss=0.47 avg=0.62\n",
            "[17460 | 4050.90] loss=0.30 avg=0.61\n",
            "[17470 | 4067.22] loss=0.23 avg=0.61\n",
            "[17480 | 4083.56] loss=1.30 avg=0.62\n",
            "[17490 | 4099.94] loss=1.07 avg=0.62\n",
            "[17500 | 4116.30] loss=0.31 avg=0.62\n",
            "[17510 | 4132.64] loss=0.44 avg=0.62\n",
            "[17520 | 4149.00] loss=0.90 avg=0.62\n",
            "[17530 | 4165.36] loss=0.85 avg=0.62\n",
            "[17540 | 4181.73] loss=0.42 avg=0.62\n",
            "[17550 | 4198.07] loss=0.59 avg=0.62\n",
            "[17560 | 4214.42] loss=0.31 avg=0.62\n",
            "[17570 | 4230.78] loss=0.23 avg=0.61\n",
            "[17580 | 4247.16] loss=1.43 avg=0.62\n",
            "[17590 | 4263.57] loss=0.53 avg=0.62\n",
            "[17600 | 4279.98] loss=0.30 avg=0.62\n",
            "[17610 | 4296.33] loss=0.48 avg=0.62\n",
            "[17620 | 4312.68] loss=0.86 avg=0.62\n",
            "[17630 | 4329.03] loss=0.14 avg=0.61\n",
            "[17640 | 4345.41] loss=0.26 avg=0.61\n",
            "[17650 | 4361.80] loss=0.32 avg=0.61\n",
            "[17660 | 4378.22] loss=0.29 avg=0.60\n",
            "[17670 | 4394.62] loss=1.18 avg=0.61\n",
            "[17680 | 4411.04] loss=0.33 avg=0.61\n",
            "[17690 | 4427.44] loss=0.19 avg=0.60\n",
            "[17700 | 4443.81] loss=0.36 avg=0.60\n",
            "[17710 | 4460.19] loss=0.66 avg=0.60\n",
            "[17720 | 4476.55] loss=1.62 avg=0.61\n",
            "[17730 | 4492.88] loss=0.34 avg=0.61\n",
            "[17740 | 4509.19] loss=0.60 avg=0.61\n",
            "[17750 | 4525.54] loss=1.52 avg=0.62\n",
            "[17760 | 4541.87] loss=0.27 avg=0.61\n",
            "[17770 | 4558.23] loss=1.25 avg=0.62\n",
            "[17780 | 4574.62] loss=0.35 avg=0.62\n",
            "[17790 | 4591.00] loss=0.81 avg=0.62\n",
            "[17800 | 4607.37] loss=0.34 avg=0.62\n",
            "[17810 | 4623.75] loss=0.87 avg=0.62\n",
            "[17820 | 4640.12] loss=1.12 avg=0.62\n",
            "[17830 | 4656.50] loss=0.59 avg=0.62\n",
            "[17840 | 4672.91] loss=1.28 avg=0.63\n",
            "[17850 | 4689.34] loss=0.21 avg=0.63\n",
            "[17860 | 4705.72] loss=1.21 avg=0.63\n",
            "[17870 | 4722.08] loss=1.16 avg=0.64\n",
            "[17880 | 4738.44] loss=0.25 avg=0.63\n",
            "[17890 | 4754.77] loss=0.38 avg=0.63\n",
            "[17900 | 4771.07] loss=0.39 avg=0.63\n",
            "[17910 | 4787.37] loss=0.15 avg=0.62\n",
            "[17920 | 4803.69] loss=0.25 avg=0.62\n",
            "[17930 | 4820.05] loss=0.24 avg=0.62\n",
            "[17940 | 4836.43] loss=0.63 avg=0.62\n",
            "[17950 | 4852.82] loss=0.53 avg=0.62\n",
            "[17960 | 4869.23] loss=0.40 avg=0.61\n",
            "[17970 | 4885.60] loss=0.12 avg=0.61\n",
            "[17980 | 4901.99] loss=0.55 avg=0.61\n",
            "[17990 | 4918.33] loss=0.32 avg=0.60\n",
            "[18000 | 4934.62] loss=1.00 avg=0.61\n",
            "Saving checkpoint/mm_model_355M_v01/model-18000\n",
            "======== SAMPLE 1 ========\n",
            ":\n",
            "To Bóg;\n",
            "Co mnie dokonał miłości osób,\n",
            "Z kim dzielił ambit —\n",
            "Byłem jeden i drugi księżyc całe\n",
            "I trzewska sekała moc ducha,\n",
            "I szepcesz, kiedy ciesząc ciężką rolę,\n",
            "Duszę mi próżne odgadła miała\n",
            "Młodzieńczego rzeczywistość typeą.\n",
            "Czyżby cię znał ci jeden i drugi księżyc całe\n",
            "I trzewska sekała moc ducha,\n",
            "A młodzieńczego rzeczywistość typeą?\n",
            "Czyżby cię znał, na które kładzie ciało,\n",
            "W której milczą anielską chwałą?\n",
            "I tak zaklinam na dach słomianych rozłączę\n",
            "I myną rozwiądniami przeczucie,\n",
            "Któremu, jak z popiołów, pozostało,\n",
            "Jak sokół wstydem ci przeczuciem.\n",
            "Ach! komu inne a księżyc powtórzy,\n",
            "Oczy i myśli buchnie zanucę —\n",
            "Tyś mnie nie słuchał, a tę przecież słyszy\n",
            "Przyjmę za sobą do mieczysko miłości;\n",
            "Wróciłbym więc do dzieła oczym jadem,\n",
            "I przyniósłbym swoję dziś wśród ludzi:\n",
            "Zepchnąłbym, ze drzewa powstające gadem,\n",
            "I świeże buchnęło w takim innym duchu,\n",
            "Przyleciałbym dla mnie już świat z kielicha,\n",
            "Chciałabym spokój zwracać nie ma dla ducha,\n",
            "Z wielkiego mierzy uśmiechu słuchać dłoń,\n",
            "Bo w niej ni życia leci takie słuchać,\n",
            "Tyś niepomny, czułej rozłączenia,\n",
            "Myślą, że jedynie jego owiane.\n",
            "Jak helota, palące starości swiętnia,\n",
            "Sprzętna, czemuż nie widać z tobą w świecie,\n",
            "Wyznajdzie helota, biedna, lub ciężarem,\n",
            "Odepchnął znacznym twą siłę i męztwo,\n",
            "Myśl, że helmut niezdolnymi złymiła.\n",
            "Że jedną, czynem echowe ulata\n",
            "Wyzłoście niepomarszczyła bojowe;\n",
            "A czynów tém dały aniołom słowo,\n",
            "Że helmut nie strzegły przyjąć żyła,\n",
            "I że ona jeszcze rzecz — — ona!\n",
            "Gdym sam stanął na miasto, czy wdrócisz,\n",
            "Czy wodzisz krwi i cierpi, czy wschód doskórnie,\n",
            "Czy smutniejszą piosnkę zażegł przysłaginą,\n",
            "Czy buchnął życie\n",
            "\n",
            "[18010 | 4979.54] loss=0.10 avg=0.60\n",
            "[18020 | 4995.85] loss=0.88 avg=0.61\n",
            "[18030 | 5012.14] loss=1.25 avg=0.61\n",
            "[18040 | 5028.50] loss=0.22 avg=0.61\n",
            "[18050 | 5044.87] loss=0.81 avg=0.61\n",
            "[18060 | 5061.30] loss=0.73 avg=0.61\n",
            "[18070 | 5077.70] loss=0.70 avg=0.61\n",
            "[18080 | 5094.07] loss=0.66 avg=0.61\n",
            "[18090 | 5110.42] loss=0.51 avg=0.61\n",
            "[18100 | 5126.72] loss=0.70 avg=0.61\n",
            "[18110 | 5143.03] loss=0.85 avg=0.62\n",
            "[18120 | 5159.38] loss=0.45 avg=0.61\n",
            "[18130 | 5175.73] loss=1.50 avg=0.62\n",
            "[18140 | 5192.08] loss=0.41 avg=0.62\n",
            "[18150 | 5208.47] loss=0.97 avg=0.62\n",
            "[18160 | 5224.84] loss=0.29 avg=0.62\n",
            "[18170 | 5241.22] loss=0.72 avg=0.62\n",
            "[18180 | 5257.60] loss=0.35 avg=0.62\n",
            "[18190 | 5274.01] loss=0.27 avg=0.62\n",
            "[18200 | 5290.38] loss=0.85 avg=0.62\n",
            "[18210 | 5306.76] loss=0.62 avg=0.62\n",
            "[18220 | 5323.14] loss=0.27 avg=0.61\n",
            "[18230 | 5339.50] loss=0.58 avg=0.61\n",
            "[18240 | 5355.87] loss=0.39 avg=0.61\n",
            "[18250 | 5372.23] loss=0.31 avg=0.61\n",
            "[18260 | 5388.57] loss=0.51 avg=0.61\n",
            "[18270 | 5404.91] loss=0.29 avg=0.60\n",
            "[18280 | 5421.27] loss=0.16 avg=0.60\n",
            "[18290 | 5437.67] loss=0.17 avg=0.60\n",
            "[18300 | 5454.07] loss=0.42 avg=0.59\n",
            "[18310 | 5470.47] loss=0.59 avg=0.59\n",
            "[18320 | 5486.88] loss=0.10 avg=0.59\n",
            "[18330 | 5503.28] loss=0.57 avg=0.59\n",
            "[18340 | 5519.66] loss=0.18 avg=0.58\n",
            "[18350 | 5536.02] loss=0.14 avg=0.58\n",
            "[18360 | 5552.38] loss=0.25 avg=0.58\n",
            "[18370 | 5568.73] loss=0.85 avg=0.58\n",
            "[18380 | 5585.07] loss=1.12 avg=0.58\n",
            "[18390 | 5601.41] loss=0.91 avg=0.59\n",
            "[18400 | 5617.78] loss=0.50 avg=0.59\n",
            "[18410 | 5634.15] loss=0.16 avg=0.58\n",
            "[18420 | 5650.54] loss=0.58 avg=0.58\n",
            "[18430 | 5666.91] loss=0.63 avg=0.58\n",
            "[18440 | 5683.31] loss=0.57 avg=0.58\n",
            "[18450 | 5699.70] loss=0.14 avg=0.58\n",
            "[18460 | 5716.11] loss=0.21 avg=0.57\n",
            "[18470 | 5732.52] loss=0.29 avg=0.57\n",
            "[18480 | 5748.92] loss=0.38 avg=0.57\n",
            "[18490 | 5765.31] loss=0.36 avg=0.57\n",
            "[18500 | 5781.68] loss=0.16 avg=0.56\n",
            "[18510 | 5798.07] loss=1.41 avg=0.57\n",
            "[18520 | 5814.48] loss=0.10 avg=0.57\n",
            "[18530 | 5830.86] loss=0.97 avg=0.57\n",
            "[18540 | 5847.24] loss=0.23 avg=0.57\n",
            "[18550 | 5863.65] loss=1.22 avg=0.57\n",
            "[18560 | 5880.03] loss=0.40 avg=0.57\n",
            "[18570 | 5896.45] loss=0.81 avg=0.58\n",
            "[18580 | 5912.83] loss=0.29 avg=0.57\n",
            "[18590 | 5929.21] loss=0.25 avg=0.57\n",
            "[18600 | 5945.60] loss=0.38 avg=0.57\n",
            "[18610 | 5961.99] loss=0.19 avg=0.56\n",
            "[18620 | 5978.41] loss=0.30 avg=0.56\n",
            "[18630 | 5994.77] loss=0.62 avg=0.56\n",
            "[18640 | 6011.11] loss=0.39 avg=0.56\n",
            "[18650 | 6027.44] loss=0.60 avg=0.56\n",
            "[18660 | 6043.79] loss=0.83 avg=0.56\n",
            "[18670 | 6060.13] loss=0.14 avg=0.56\n",
            "[18680 | 6076.46] loss=0.19 avg=0.55\n",
            "[18690 | 6092.78] loss=0.25 avg=0.55\n",
            "[18700 | 6109.10] loss=0.75 avg=0.55\n",
            "[18710 | 6125.43] loss=0.20 avg=0.55\n",
            "[18720 | 6141.78] loss=0.29 avg=0.55\n",
            "[18730 | 6158.12] loss=0.48 avg=0.55\n",
            "[18740 | 6174.44] loss=0.13 avg=0.54\n",
            "[18750 | 6190.78] loss=0.17 avg=0.54\n",
            "[18760 | 6207.10] loss=0.36 avg=0.54\n",
            "[18770 | 6223.42] loss=0.48 avg=0.54\n",
            "[18780 | 6239.76] loss=0.40 avg=0.53\n",
            "[18790 | 6256.12] loss=0.21 avg=0.53\n",
            "[18800 | 6272.50] loss=1.54 avg=0.54\n",
            "[18810 | 6288.87] loss=0.29 avg=0.54\n",
            "[18820 | 6305.29] loss=0.23 avg=0.54\n",
            "[18830 | 6321.68] loss=0.31 avg=0.53\n",
            "[18840 | 6338.03] loss=0.60 avg=0.53\n",
            "[18850 | 6354.41] loss=0.14 avg=0.53\n",
            "[18860 | 6370.78] loss=0.51 avg=0.53\n",
            "[18870 | 6387.19] loss=0.55 avg=0.53\n",
            "[18880 | 6403.55] loss=0.70 avg=0.53\n",
            "[18890 | 6419.90] loss=0.55 avg=0.53\n",
            "[18900 | 6436.23] loss=0.47 avg=0.53\n",
            "[18910 | 6452.59] loss=0.15 avg=0.53\n",
            "[18920 | 6468.94] loss=0.27 avg=0.52\n",
            "[18930 | 6485.30] loss=0.45 avg=0.52\n",
            "[18940 | 6501.63] loss=0.40 avg=0.52\n",
            "[18950 | 6517.98] loss=0.32 avg=0.52\n",
            "[18960 | 6534.31] loss=0.51 avg=0.52\n",
            "[18970 | 6550.63] loss=0.16 avg=0.52\n",
            "[18980 | 6566.97] loss=0.74 avg=0.52\n",
            "[18990 | 6583.37] loss=0.14 avg=0.52\n",
            "[19000 | 6599.73] loss=0.52 avg=0.52\n",
            "Saving checkpoint/mm_model_355M_v01/model-19000\n",
            "[19010 | 6622.78] loss=0.78 avg=0.52\n",
            "[19020 | 6639.42] loss=0.35 avg=0.52\n",
            "[19030 | 6655.88] loss=0.65 avg=0.52\n",
            "[19040 | 6672.22] loss=0.18 avg=0.51\n",
            "[19050 | 6688.50] loss=0.18 avg=0.51\n",
            "[19060 | 6704.84] loss=0.35 avg=0.51\n",
            "[19070 | 6721.26] loss=0.61 avg=0.51\n",
            "[19080 | 6737.71] loss=0.28 avg=0.51\n",
            "[19090 | 6754.04] loss=0.68 avg=0.51\n",
            "[19100 | 6770.35] loss=0.31 avg=0.51\n",
            "[19110 | 6786.64] loss=0.25 avg=0.51\n",
            "[19120 | 6802.97] loss=0.15 avg=0.50\n",
            "[19130 | 6819.32] loss=0.40 avg=0.50\n",
            "[19140 | 6835.72] loss=0.38 avg=0.50\n",
            "[19150 | 6852.14] loss=0.26 avg=0.50\n",
            "[19160 | 6868.51] loss=0.15 avg=0.49\n",
            "[19170 | 6884.87] loss=0.15 avg=0.49\n",
            "[19180 | 6901.19] loss=0.45 avg=0.49\n",
            "[19190 | 6917.49] loss=0.34 avg=0.49\n",
            "[19200 | 6933.78] loss=0.79 avg=0.49\n",
            "[19210 | 6950.08] loss=0.21 avg=0.49\n",
            "[19220 | 6966.41] loss=1.27 avg=0.50\n",
            "[19230 | 6982.76] loss=0.18 avg=0.49\n",
            "[19240 | 6999.08] loss=0.86 avg=0.50\n",
            "[19250 | 7015.44] loss=0.33 avg=0.49\n",
            "[19260 | 7031.77] loss=0.30 avg=0.49\n",
            "[19270 | 7048.12] loss=0.32 avg=0.49\n",
            "[19280 | 7064.50] loss=0.28 avg=0.49\n",
            "[19290 | 7080.88] loss=0.27 avg=0.49\n",
            "[19300 | 7097.29] loss=0.17 avg=0.48\n",
            "[19310 | 7113.68] loss=0.43 avg=0.48\n",
            "[19320 | 7130.00] loss=0.44 avg=0.48\n",
            "[19330 | 7146.33] loss=0.18 avg=0.48\n",
            "[19340 | 7162.63] loss=0.20 avg=0.48\n",
            "[19350 | 7178.97] loss=0.94 avg=0.48\n",
            "[19360 | 7195.35] loss=0.42 avg=0.48\n",
            "[19370 | 7211.77] loss=0.62 avg=0.48\n",
            "[19380 | 7228.19] loss=0.50 avg=0.48\n",
            "[19390 | 7244.57] loss=0.66 avg=0.48\n",
            "[19400 | 7260.94] loss=1.22 avg=0.49\n",
            "[19410 | 7277.32] loss=0.47 avg=0.49\n",
            "[19420 | 7293.65] loss=0.17 avg=0.49\n",
            "[19430 | 7310.02] loss=0.27 avg=0.49\n",
            "[19440 | 7326.33] loss=0.31 avg=0.48\n",
            "[19450 | 7342.60] loss=0.67 avg=0.49\n",
            "[19460 | 7358.94] loss=0.19 avg=0.48\n",
            "[19470 | 7375.26] loss=0.15 avg=0.48\n",
            "[19480 | 7391.59] loss=0.20 avg=0.48\n",
            "[19490 | 7407.92] loss=0.44 avg=0.48\n",
            "[19500 | 7424.26] loss=1.05 avg=0.48\n",
            "[19510 | 7440.59] loss=0.41 avg=0.48\n",
            "[19520 | 7456.90] loss=0.36 avg=0.48\n",
            "[19530 | 7473.22] loss=0.14 avg=0.48\n",
            "[19540 | 7489.55] loss=0.17 avg=0.47\n",
            "[19550 | 7505.86] loss=0.23 avg=0.47\n",
            "[19560 | 7522.18] loss=0.36 avg=0.47\n",
            "[19570 | 7538.53] loss=0.23 avg=0.47\n",
            "[19580 | 7554.88] loss=0.26 avg=0.47\n",
            "[19590 | 7571.27] loss=0.70 avg=0.47\n",
            "[19600 | 7587.67] loss=0.88 avg=0.47\n",
            "[19610 | 7604.05] loss=0.28 avg=0.47\n",
            "[19620 | 7620.45] loss=0.41 avg=0.47\n",
            "[19630 | 7636.87] loss=0.44 avg=0.47\n",
            "[19640 | 7653.29] loss=0.77 avg=0.47\n",
            "[19650 | 7669.66] loss=0.42 avg=0.47\n",
            "[19660 | 7686.01] loss=1.36 avg=0.48\n",
            "[19670 | 7702.30] loss=0.34 avg=0.48\n",
            "[19680 | 7718.63] loss=0.27 avg=0.48\n",
            "[19690 | 7734.96] loss=0.30 avg=0.48\n",
            "[19700 | 7751.26] loss=0.24 avg=0.47\n",
            "[19710 | 7767.60] loss=0.23 avg=0.47\n",
            "[19720 | 7783.93] loss=0.23 avg=0.47\n",
            "[19730 | 7800.26] loss=1.45 avg=0.48\n",
            "[19740 | 7816.63] loss=0.22 avg=0.48\n",
            "[19750 | 7833.02] loss=0.34 avg=0.47\n",
            "[19760 | 7849.38] loss=0.11 avg=0.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhMeKShzJ8Do"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='mm_model_355M_v01')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkqT0S1ZJ5mZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49993b08-fa4f-46ac-f508-5235c1eda10f"
      },
      "source": [
        "#tylko jeśli załadowaliśmy checkpoint bez trenowania\n",
        "#sess = gpt2.start_tf_sess()\n",
        "#gpt2.load_gpt2(sess, run_name='mm_model_355M_v01')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/mm_model_355M_v01/model-15000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/mm_model_355M_v01/model-15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaUsoHDnxY0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd786c8e-b0c4-4427-d9e2-d97e1d68f969"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              run_name='mm_model_355M_v01',\n",
        "              length=150,\n",
        "              temperature=0.4,\n",
        "              prefix=\"O żono moja luba\",\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O żono moja luba,\n",
            "W ten ciche me niosąc błyska...\n",
            "Ktoś wciągnął: „niechże go się trzyma;\n",
            "Nie ma dla gościńca, nie ma dla ducha...” \n",
            "Niechaj kochany kwiatek mogiły\n",
            "Wielki ciężki kwiatek nad wyrazem...\n",
            "Niech kwiatek nad wyrazem,\n",
            "A nieśmiertelnym śnieżnym progom\n",
            "Wielkim pow\n",
            "====================\n",
            "O żono moja luba,\n",
            "Luba, luba, prócz tęskniąca,\n",
            "Na nim ludzi, lub zbawieniem,\n",
            "Człowiek dziedzictwo krąży.\n",
            "Człowiek mówi: «Bądź nam!» — czeka\n",
            "O najświętszą dolę.\n",
            "Ach! ja szanuję — szanuję\n",
            "O najstrożniejszej zorzy!\n",
            "O, pomnij ty się, ty święts\n",
            "====================\n",
            "O żono moja luba,\n",
            "Co ma być może, jakby wyśnione.\n",
            "Wyśnione mnie obala,\n",
            "Którą wszelki duch mój odchodził,\n",
            "I oby nigdy nie powrócę.\n",
            "Na kogo czekał, przystołuje,\n",
            "Czekał i wstyd za co!\n",
            "Być może, było to złudzeniem,\n",
            "Że to ona jest niebem,\n",
            "Wystąpiła oświadczyć kam\n",
            "====================\n",
            "O żono moja luba,\n",
            "I w rozlewie kwiaty na roli.\n",
            "Nadzieją, przyjmij, kłamstwo i dumne,\n",
            "Kłamstwo, przyjmij, serce i głuchy...\n",
            "Czuję, jak w dumny ból i żal nie wie\n",
            "Ani w proch mroków zmienny na dnie,\n",
            "Ale w proch niebios i ducha nie boję,\n",
            "Bo kwiat się rozlewa łączy kurczowo,\n",
            "Bo ka\n",
            "====================\n",
            "O żono moja luba,\n",
            "Co ma być może, jak ty,\n",
            "Byłaż to łezka z rana?\n",
            "Czyżby cię znowu\n",
            "Żono moja luba,\n",
            "Byłaż to łezka z rana?\n",
            "Na ustach twoich róża\n",
            "Światłością dziewicę,\n",
            "By cię znowu\n",
            "Pod twej komnacie\n",
            "Wybawicie razem?\n",
            "Czyżby cię znowu\n",
            "Ustach twoich róż\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQLF7iiMxd1j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}